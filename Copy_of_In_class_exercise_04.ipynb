{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of In-class-exercise-04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kate5-7-2021/Kate_INFO5731_Spring2021/blob/main/Copy_of_In_class_exercise_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuX00KHNeSpw"
      },
      "source": [
        "# **The fourth in-class-exercise (20 points in total, 2/9/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vTOb03hG1f"
      },
      "source": [
        "# 1. Text Data Preprocessing\n",
        "\n",
        "Here is a [legal case](https://github.com/unt-iialab/info5731_spring2021/blob/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt) we collected from westlaw, please follow the steps we mentioned in lesson 5 to clean the data:\n",
        "\n",
        "\n",
        "\n",
        "## 1.1 Basic feature extraction using text data (4 points)\n",
        "\n",
        "*   Number of sentences\n",
        "*   Number of words\n",
        "*   Number of characters\n",
        "*   Average word length\n",
        "*   Number of stopwords\n",
        "*   Number of special characters\n",
        "*   Number of numerics\n",
        "*   Number of uppercase words\n",
        "\n",
        "## 1.2 Basic Text Pre-processing of text data (4 points)\n",
        "\n",
        "*   Lower casing\n",
        "*   Punctuation removal\n",
        "*   Stopwords removal\n",
        "*   Frequent words removal\n",
        "*   Rare words removal\n",
        "*   Spelling correction\n",
        "*   Tokenization\n",
        "*   Stemming\n",
        "*   Lemmatization\n",
        "\n",
        "## 1.3 Save all the **clean sentences** to a **csv file** (one column, each raw is a sentence) after finishing all the steps above. (4 points)\n",
        "\n",
        "\n",
        "## 1.4 Advance Text Processing (Extra credit: 4 points)\n",
        "\n",
        "*   Calculate the term frequency of all the terms.\n",
        "*   Print out top 10 1-gram, top 10 2-grams, and top 10 3-grams terms as features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WknOwiq7NER"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFqiEUZXCsNT"
      },
      "source": [
        "#Start Coding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG0fjQD7_V77"
      },
      "source": [
        "###1.1 Basic feature extraction using text data\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR0L3_CreM_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125e23fc-ef77-4fa2-d0bc-6c2c84dda42a"
      },
      "source": [
        "import pandas as pd\n",
        "url=\"https://raw.githubusercontent.com/unt-iialab/info5731_spring2021/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt\"\n",
        "\n",
        "case = pd.read_csv(url , error_bad_lines=False, header=None)      # create dataframe from csv file\n",
        "                                                     #print the first 5 rows"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 7: expected 1 fields, saw 2\\nSkipping line 19: expected 1 fields, saw 2\\nSkipping line 25: expected 1 fields, saw 4\\nSkipping line 28: expected 1 fields, saw 44\\nSkipping line 29: expected 1 fields, saw 12\\nSkipping line 31: expected 1 fields, saw 31\\nSkipping line 32: expected 1 fields, saw 8\\nSkipping line 33: expected 1 fields, saw 6\\nSkipping line 34: expected 1 fields, saw 5\\nSkipping line 37: expected 1 fields, saw 2\\nSkipping line 39: expected 1 fields, saw 25\\nSkipping line 40: expected 1 fields, saw 9\\nSkipping line 41: expected 1 fields, saw 21\\nSkipping line 42: expected 1 fields, saw 66\\nSkipping line 43: expected 1 fields, saw 10\\nSkipping line 44: expected 1 fields, saw 15\\nSkipping line 45: expected 1 fields, saw 2\\nSkipping line 49: expected 1 fields, saw 2\\nSkipping line 50: expected 1 fields, saw 6\\nSkipping line 51: expected 1 fields, saw 8\\nSkipping line 52: expected 1 fields, saw 15\\nSkipping line 53: expected 1 fields, saw 33\\nSkipping line 55: expected 1 fields, saw 2\\nSkipping line 67: expected 1 fields, saw 3\\nSkipping line 68: expected 1 fields, saw 2\\nSkipping line 73: expected 1 fields, saw 2\\nSkipping line 74: expected 1 fields, saw 3\\nSkipping line 81: expected 1 fields, saw 3\\nSkipping line 88: expected 1 fields, saw 3\\nSkipping line 95: expected 1 fields, saw 3\\nSkipping line 102: expected 1 fields, saw 3\\nSkipping line 103: expected 1 fields, saw 6\\nSkipping line 109: expected 1 fields, saw 3\\nSkipping line 116: expected 1 fields, saw 3\\nSkipping line 117: expected 1 fields, saw 2\\nSkipping line 124: expected 1 fields, saw 6\\nSkipping line 138: expected 1 fields, saw 3\\nSkipping line 139: expected 1 fields, saw 5\\nSkipping line 144: expected 1 fields, saw 3\\nSkipping line 150: expected 1 fields, saw 3\\nSkipping line 151: expected 1 fields, saw 7\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXQJzmhrQc0L",
        "outputId": "e608b531-6afd-44b6-95cc-55c8eab99c5b"
      },
      "source": [
        "case.info()"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 107 entries, 0 to 106\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       107 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 984.0+ bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "mrdLbWqrQKN2",
        "outputId": "8284515d-2bb6-4382-f676-edb673224e20"
      },
      "source": [
        "case.head(5)"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           0\n",
              "0                 5 Ala. 740\n",
              "1  Supreme Court of Alabama.\n",
              "2                      ADAMS\n",
              "3                         v.\n",
              "4         TANNER AND HORTON."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 343
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "iO0rWN_4bGll",
        "outputId": "f112d5e1-d91f-42eb-897f-706b385a7405"
      },
      "source": [
        "case.columns = ['sentence']                             # create header for dataframe column\r\n",
        "case.head(5)"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence\n",
              "0                 5 Ala. 740\n",
              "1  Supreme Court of Alabama.\n",
              "2                      ADAMS\n",
              "3                         v.\n",
              "4         TANNER AND HORTON."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_wZxFUeIk42",
        "outputId": "e107fd56-c37d-48da-af91-2d647f7eedd8"
      },
      "source": [
        "print(len(case['sentence']))                         #number of the sentences"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ZSLz7AjBc-j5",
        "outputId": "34b89435-5f76-4d34-c007-84ecc362bea0"
      },
      "source": [
        "#num_words=df['sentence'].apply(lambdax: len(str(x).split(' ')\r\n",
        "#df['sent_words'] = len(num_words)\r\n",
        "case['num_words']=case['sentence'].apply(lambda x: len(str(x).split(' ')))   #number of words\r\n",
        "case.head(5)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_char</th>\n",
              "      <th>num_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  num_char  num_words\n",
              "0                 5 Ala. 740        10          3\n",
              "1  Supreme Court of Alabama.        25          4\n",
              "2                      ADAMS         5          1\n",
              "3                         v.         2          1\n",
              "4         TANNER AND HORTON.        18          3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "qcbOPqKiKeWz",
        "outputId": "179b3d11-62d7-41f7-c51a-6b4bbebc575f"
      },
      "source": [
        "case['num_char']= case['sentence'].str.len()     #number of charracters\r\n",
        "\r\n",
        "case[['sentence','num_words','num_char']].head(5)"
      ],
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_char</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  num_words  num_char\n",
              "0                 5 Ala. 740          3        10\n",
              "1  Supreme Court of Alabama.          4        25\n",
              "2                      ADAMS          1         5\n",
              "3                         v.          1         2\n",
              "4         TANNER AND HORTON.          3        18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "BVmvDs87hHBo",
        "outputId": "2dc874e5-237b-4ca2-d69b-6968d3546169"
      },
      "source": [
        "def avg_word_len(sentence):\r\n",
        "  words = sentence.split()\r\n",
        "  #return (sum(len(word) for word in words)/len(words))   # with this line of the code there is an error for division by zero\r\n",
        "                                                          # so the use of if/else will solve this issue\r\n",
        "\r\n",
        "  if len(words)!=0:\r\n",
        "    return (sum(len(word) for word in words)/len(words))\r\n",
        "  else:\r\n",
        "    return 0\r\n",
        "\r\n",
        "#case['avg_word_len']= case['num_char']/case['num_words']                 #this line and the next line both have the results of avarage of\r\n",
        "case['avg_word_len']=case['sentence'].apply(lambda x: avg_word_len(x))    # word lenght, but their results in some cases are different numbers\r\n",
        "case[['sentence','num_words','num_char','avg_word_len']].head(5)\r\n",
        "\r\n"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_char</th>\n",
              "      <th>avg_word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>5.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>5.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  num_words  num_char  avg_word_len\n",
              "0                 5 Ala. 740          3        10      2.666667\n",
              "1  Supreme Court of Alabama.          4        25      5.500000\n",
              "2                      ADAMS          1         5      5.000000\n",
              "3                         v.          1         2      2.000000\n",
              "4         TANNER AND HORTON.          3        18      5.333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "e8vOK2fXRkiB",
        "outputId": "f4fba96b-47a4-43ea-a3f7-76240c7254cd"
      },
      "source": [
        "case['avg_word_len']= case['num_char']/case['num_words']  \r\n",
        "\r\n",
        "case.sample(5)                                   #get the sample of avarage word leght with this line of code"
      ],
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_char</th>\n",
              "      <th>num_words</th>\n",
              "      <th>avg_word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>Treatment</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Dec Term 1876</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>4.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>4 Cases that cite this headnote</td>\n",
              "      <td>31</td>\n",
              "      <td>6</td>\n",
              "      <td>5.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[2]</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Chattel Mortgages</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>8.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           sentence  num_char  num_words  avg_word_len\n",
              "82                        Treatment         9          1      9.000000\n",
              "32                    Dec Term 1876        13          3      4.333333\n",
              "12  4 Cases that cite this headnote        31          6      5.166667\n",
              "13                              [2]         3          1      3.000000\n",
              "10                Chattel Mortgages        17          2      8.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmlj6Qr8es_V",
        "outputId": "91923f7b-8942-4640-8311-3ad7081a571e"
      },
      "source": [
        "!pip install nltk                         #install the necessary packages\r\n",
        "!pip install stopword\r\n",
        "import stopword\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: stopword in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "yfimuI5WjMca",
        "outputId": "d6b09bd0-4e9b-44ac-b027-70120d0e2bec"
      },
      "source": [
        "stop_list=stopwords.words('english')\r\n",
        "case['stopwords']=case['sentence'].apply(lambda x: len([item for item in x.split() if item in stop_list]))    #Num of stopwords\r\n",
        "case[['sentence','num_words','num_char','avg_word_len','stopwords']].head(5)\r\n",
        "\r\n"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_char</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>stopwords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  num_words  num_char  avg_word_len  stopwords\n",
              "0                 5 Ala. 740          3        10      3.333333          0\n",
              "1  Supreme Court of Alabama.          4        25      6.250000          1\n",
              "2                      ADAMS          1         5      5.000000          0\n",
              "3                         v.          1         2      2.000000          0\n",
              "4         TANNER AND HORTON.          3        18      6.000000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Z1aF-KDS8e"
      },
      "source": [
        "#case['stopwords']=case['sentence'].apply(lambda x: [item for item in x.split() if item in stop_list])  #the list of stopwords in each sentence\r\n",
        "#case[['sentence','num_words','num_char','avg_word_len','stopwords']].head(5)"
      ],
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6ZibEhpiUQf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "674c5189-a709-4d81-85d6-b682f19c73d1"
      },
      "source": [
        "case['periods'] = case['sentence'].apply(lambda x: len([item for item in x.split() if item.endswith('.')])) # Number of special character\r\n",
        "case[['sentence','num_words','num_char','avg_word_len','stopwords','periods']].head(5)       "
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_char</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>periods</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  num_words  ...  stopwords  periods\n",
              "0                 5 Ala. 740          3  ...          0        1\n",
              "1  Supreme Court of Alabama.          4  ...          1        1\n",
              "2                      ADAMS          1  ...          0        0\n",
              "3                         v.          1  ...          0        1\n",
              "4         TANNER AND HORTON.          3  ...          0        1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Pj9dj2yX9BEM",
        "outputId": "31fabc3a-c274-449e-f0ab-9e9f4265d00e"
      },
      "source": [
        "case['numerics'] = case['sentence'].apply(lambda x: len([item for item in x.split() if item.isdigit()]))   # Number of numerics\r\n",
        "case[['sentence','num_words','num_char','avg_word_len','stopwords','periods','numerics']].head(5)"
      ],
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_char</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>periods</th>\n",
              "      <th>numerics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  num_words  num_char  ...  stopwords  periods  numerics\n",
              "0                 5 Ala. 740          3        10  ...          0        1         2\n",
              "1  Supreme Court of Alabama.          4        25  ...          1        1         0\n",
              "2                      ADAMS          1         5  ...          0        0         0\n",
              "3                         v.          1         2  ...          0        1         0\n",
              "4         TANNER AND HORTON.          3        18  ...          0        1         0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVx2y-1dBmzk"
      },
      "source": [
        "# Number of numerics: shows the list of the numeric values\r\n",
        "#case['numerics'] = case['sentence'].apply(lambda x: [item for item in x.split() if item.isdigit()])\r\n",
        "#case[['sentence','num_words','num_char','avg_word_len','stopwords','periods','numerics']].head(5)"
      ],
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Cof0BqWI9BTA",
        "outputId": "66cebd3e-68ff-4647-f097-75bb5f805683"
      },
      "source": [
        "# Number of uppercase: it counts the words with all uppercase letters\r\n",
        "case['upper_case'] = case['sentence'].apply(lambda x: len([item for item in x.split() if item.isupper()])) \r\n",
        "case[['sentence','num_words','num_char','avg_word_len','stopwords','periods','numerics','upper_case']].head(5)   \r\n",
        "                                                                                    "
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_char</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>periods</th>\n",
              "      <th>numerics</th>\n",
              "      <th>upper_case</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 Ala. 740</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court of Alabama.</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ADAMS</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TANNER AND HORTON.</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence  num_words  ...  numerics  upper_case\n",
              "0                 5 Ala. 740          3  ...         2           0\n",
              "1  Supreme Court of Alabama.          4  ...         0           0\n",
              "2                      ADAMS          1  ...         0           1\n",
              "3                         v.          1  ...         0           0\n",
              "4         TANNER AND HORTON.          3  ...         0           3\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTIa9jEt9Bco"
      },
      "source": [
        "# Number of uppercase: it shows the list of words with all uppercase letters in each sentence\r\n",
        "#case['upper_case'] = case['sentence'].apply(lambda x: [item for item in x.split() if item.isupper()]) \r\n",
        "#case[['sentence','num_words','num_char','avg_word_len','stopwords','periods','numerics','upper_case']].head(5)"
      ],
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNQDuNXb9Bwj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo9JBaQxDCpS"
      },
      "source": [
        "###1.2 Basic Text Pre-processing of text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "wgaPWQZeDIMH",
        "outputId": "f7025567-a3bd-4fb7-9990-847655c9d99a"
      },
      "source": [
        "case['sentence'] = case['sentence'].str.lower()      #Change all the letters to lowercase\r\n",
        "case[['sentence']].head(5)"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 ala. 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>supreme court of alabama.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tanner and horton.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    sentence\n",
              "0                 5 ala. 740\n",
              "1  supreme court of alabama.\n",
              "2                      adams\n",
              "3                         v.\n",
              "4         tanner and horton."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "254bL_vMDIRh",
        "outputId": "03f6c63a-ff0a-466e-8c2f-12c74cffd115"
      },
      "source": [
        "case['sentence'] = case['sentence'].str.replace('[^\\w\\s]','')     #one way to remove punctuation\r\n",
        "case[['sentence']].head(5)"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 ala 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>supreme court of alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tanner and horton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   sentence\n",
              "0                 5 ala 740\n",
              "1  supreme court of alabama\n",
              "2                     adams\n",
              "3                         v\n",
              "4         tanner and horton"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Q9wvLx0CDIVe",
        "outputId": "e329f365-97d0-4067-dd9d-5277f4774fe7"
      },
      "source": [
        "import string\r\n",
        "case['sentence'].str.replace('[{}]'.format(string.punctuation), '')          #another way to remove punctuation\r\n",
        "case[['sentence']].head(5)"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 ala 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>supreme court of alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tanner and horton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   sentence\n",
              "0                 5 ala 740\n",
              "1  supreme court of alabama\n",
              "2                     adams\n",
              "3                         v\n",
              "4         tanner and horton"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "IOYqiWqRDIaD",
        "outputId": "a78c476d-2756-405e-cd13-bafb9517d2ca"
      },
      "source": [
        "from nltk.corpus import stopwords\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')                          #one way to remove stopwords \r\n",
        "stop_list = stopwords.words('english')\r\n",
        "#case['sentence'] = case['sentence'].apply(lambda x: [item for item in x if item not in stop_list])\r\n",
        "case['sentence'] = case['sentence'].apply(lambda x: ' '.join(item for item in x.split() if item not in stop_list))\r\n",
        "case[['sentence']].head(5)"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 ala 740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>supreme court alabama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tanner horton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                sentence\n",
              "0              5 ala 740\n",
              "1  supreme court alabama\n",
              "2                  adams\n",
              "3                      v\n",
              "4          tanner horton"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wODq8MC3DId9"
      },
      "source": [
        "#pat = r'\\b(?:{})\\b'.format('|'.join(stop_list))                   #another way to remove stopwords\r\n",
        "#case['sentence'] = case['sentence'].str.replace(pat, '')\r\n",
        "#case['sentence'] = case['sentence'].str.replace(r'\\s+', ' ')\r\n",
        "#case[['sentence']].head()"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LD0jYAJDIiH"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5R1f1KaFUSW"
      },
      "source": [
        "#word_freq = Counter(case['sentence'])                     #one way to find most common words regardless of the stopwords\r\n",
        "#common_words = word_freq.most_common(5)\r\n",
        "#common_words"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9e9OcxhFUXS",
        "outputId": "7d6f445e-3121-43f8-89d5-ab361beb0fb5"
      },
      "source": [
        "#another way to find most common words regardless of the stopwords\r\n",
        "common= pd.Series(' '.join(case['sentence']).split()).value_counts()[:10]\r\n",
        "common"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "case       11\n",
              "v          11\n",
              "court       8\n",
              "term        7\n",
              "cited       7\n",
              "2           6\n",
              "circuit     5\n",
              "hon         5\n",
              "tried       5\n",
              "appeal      4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 368
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9O-dnMHFUbO",
        "outputId": "37cd2e3f-cba9-4418-bbec-6ab4adcd5746"
      },
      "source": [
        " #to remove most common words\r\n",
        "common = list (common.index)\r\n",
        "case['sentence'] = case['sentence'].apply(lambda x: ' '.join(item for item in x.split() if item not in common))\r\n",
        "case['sentence'].head(10)\r\n",
        "\r\n"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            5 ala 740\n",
              "1      supreme alabama\n",
              "2                adams\n",
              "3                     \n",
              "4        tanner horton\n",
              "5             synopsis\n",
              "6    writ error sumter\n",
              "7                     \n",
              "8       west headnotes\n",
              "9                    1\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQkGVJbvdG5a",
        "outputId": "37d3db72-c590-4b81-b515-a5424d062dba"
      },
      "source": [
        "#to find the last 20 rare words                         #can get different results anytime running these codes\r\n",
        "rare= pd.Series(' '.join(case['sentence']).split()).value_counts()[-20:]\r\n",
        "rare"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8             1\n",
              "end           1\n",
              "coats         1\n",
              "horton        1\n",
              "sawyer        1\n",
              "b             1\n",
              "1876          1\n",
              "moore         1\n",
              "waiver        1\n",
              "remedies      1\n",
              "etowah        1\n",
              "barbour       1\n",
              "references    1\n",
              "supreme       1\n",
              "jul           1\n",
              "lien          1\n",
              "jun           1\n",
              "joness        1\n",
              "firms         1\n",
              "reuters       1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtyAunujdG9r",
        "outputId": "ad6f9cb2-5c03-4ca5-b588-da3ad4031f50"
      },
      "source": [
        "# to remove the rare values\r\n",
        "rare = list (rare.index)\r\n",
        "case['sentence'] = case['sentence'].apply(lambda x: ' '.join(item for item in x.split() if item not in rare))\r\n",
        "case['sentence'].head(10)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            5 ala 740\n",
              "1              alabama\n",
              "2                adams\n",
              "3                     \n",
              "4               tanner\n",
              "5             synopsis\n",
              "6    writ error sumter\n",
              "7                     \n",
              "8       west headnotes\n",
              "9                    1\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1tzxJU6dHBz",
        "outputId": "5aa50227-5be3-442b-ab3a-a57d3a7c848a"
      },
      "source": [
        "# to do the spell correction     # by using [:10] limitted the results to top 10, by removing [:10] the results  \r\n",
        "from textblob import TextBlob    # would be for the rest of the data\r\n",
        "#case['sentence'][:10].apply(lambda x: str(TextBlob(x).correct()))\r\n",
        "case['sentence'] = case['sentence'].apply(lambda x: str(TextBlob(x).correct()))\r\n",
        "case['sentence'].head(10)\r\n"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            5 all 740\n",
              "1              alabama\n",
              "2                adams\n",
              "3                     \n",
              "4               manner\n",
              "5              sycosis\n",
              "6    writ error sumter\n",
              "7                     \n",
              "8       west headnotes\n",
              "9                    1\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i35zibTodHGp",
        "outputId": "7830af4a-3fb3-40b3-b843-1c321e5d81e5"
      },
      "source": [
        "# Tokenization\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPeGYn3pFUfk",
        "outputId": "a6dcdaf1-a990-46d9-d935-d1d5012b3cb8"
      },
      "source": [
        "TextBlob(case['sentence'][6]).words      # this code will tokenized the chosen sentence from dataframe"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['writ', 'error', 'sumter'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "infJbOYWFUjX",
        "outputId": "c16e389a-abb6-4c5d-c55a-eea57d5e0801"
      },
      "source": [
        "import re\r\n",
        "\r\n",
        "def tokenize(txt):\r\n",
        "  tokens = re.split('\\W+',txt)\r\n",
        "  return tokens\r\n",
        "case['tokenozed_sentence'] = case['sentence'].apply(lambda x: tokenize(x.lower()))\r\n",
        "case.head(10)"
      ],
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_char</th>\n",
              "      <th>num_words</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>periods</th>\n",
              "      <th>numerics</th>\n",
              "      <th>upper_case</th>\n",
              "      <th>tokenozed_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 all 740</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[5, all, 740]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alabama</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[alabama]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adams</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[adams]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>manner</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[manner]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sycosis</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[sycosis]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>writ error sumter</td>\n",
              "      <td>45</td>\n",
              "      <td>9</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[writ, error, sumter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>west headnotes</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[west, headnotes]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sentence  num_char  ...  upper_case     tokenozed_sentence\n",
              "0          5 all 740        10  ...           0          [5, all, 740]\n",
              "1            alabama        25  ...           0              [alabama]\n",
              "2              adams         5  ...           1                [adams]\n",
              "3                            2  ...           0                     []\n",
              "4             manner        18  ...           3               [manner]\n",
              "5            sycosis         8  ...           0              [sycosis]\n",
              "6  writ error sumter        45  ...           1  [writ, error, sumter]\n",
              "7                            1  ...           0                     []\n",
              "8     west headnotes        18  ...           0      [west, headnotes]\n",
              "9                  1         3  ...           0                    [1]\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 375
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkTguBZyvwm-",
        "outputId": "804038e6-c7dd-436b-ad31-334dbd9fa0b7"
      },
      "source": [
        "#Stemming\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "st = PorterStemmer()\r\n",
        "case['sentence'] = case['sentence'].apply(lambda x: ' '.join([st.stem(word) for word in x.split()]))\r\n",
        "case['sentence'].head(10)"
      ],
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            5 all 740\n",
              "1              alabama\n",
              "2                 adam\n",
              "3                     \n",
              "4               manner\n",
              "5               sycosi\n",
              "6    writ error sumter\n",
              "7                     \n",
              "8         west headnot\n",
              "9                    1\n",
              "Name: sentence, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 377
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiYdPDoQvwx5",
        "outputId": "ce2c4c68-0529-41e9-8489-c7f047fe1823"
      },
      "source": [
        "# Lemmatization\r\n",
        "from textblob import Word\r\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "auvHQAHKvw5L",
        "outputId": "823fe700-6839-42e9-f675-570cec59d1aa"
      },
      "source": [
        "case['sentence'] = case['sentence'].apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split()]))\r\n",
        "case.head(10)"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>num_char</th>\n",
              "      <th>num_words</th>\n",
              "      <th>avg_word_len</th>\n",
              "      <th>stopwords</th>\n",
              "      <th>periods</th>\n",
              "      <th>numerics</th>\n",
              "      <th>upper_case</th>\n",
              "      <th>tokenozed_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5 all 740</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[5, all, 740]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alabama</td>\n",
              "      <td>25</td>\n",
              "      <td>4</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[alabama]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adam</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[adams]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>manner</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[manner]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sycosi</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[sycosis]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>writ error sumter</td>\n",
              "      <td>45</td>\n",
              "      <td>9</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[writ, error, sumter]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>west headnot</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[west, headnotes]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sentence  num_char  ...  upper_case     tokenozed_sentence\n",
              "0          5 all 740        10  ...           0          [5, all, 740]\n",
              "1            alabama        25  ...           0              [alabama]\n",
              "2               adam         5  ...           1                [adams]\n",
              "3                            2  ...           0                     []\n",
              "4             manner        18  ...           3               [manner]\n",
              "5             sycosi         8  ...           0              [sycosis]\n",
              "6  writ error sumter        45  ...           1  [writ, error, sumter]\n",
              "7                            1  ...           0                     []\n",
              "8       west headnot        18  ...           0      [west, headnotes]\n",
              "9                  1         3  ...           0                    [1]\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcoE8zWh7R9D"
      },
      "source": [
        "###1.3 Save all the clean sentences to a csv file (one column, each raw is a sentence) after finishing all the steps above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr4Jumi6vw-W",
        "outputId": "d8ba4f66-20fd-48c6-8e78-d25663552253"
      },
      "source": [
        "import numpy as np\r\n",
        "#in the last dataframe results there are some rows without any sentences. So, to convert to csv with one colimn with sentence in each row,\r\n",
        "#first the empty rows must be removed, to do that replace the empty space with NaN and then remove any rows contain NaN\r\n",
        "case['sentence'].replace('',np.nan, inplace = True)\r\n",
        "case['sentence']\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        5 all 740\n",
              "1                          alabama\n",
              "2                             adam\n",
              "3                              NaN\n",
              "4                           manner\n",
              "                  ...             \n",
              "102                    file situat\n",
              "103                  neg treatment\n",
              "104    neg treatment result situat\n",
              "105                        histori\n",
              "106          histori result situat\n",
              "Name: sentence, Length: 107, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zf6Vj55vxDH",
        "outputId": "621eba13-f152-4690-cdd5-3170db89ce7d"
      },
      "source": [
        "case.dropna(subset=['sentence'],inplace = True)\r\n",
        "case['sentence']"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                        5 all 740\n",
              "1                          alabama\n",
              "2                             adam\n",
              "4                           manner\n",
              "5                           sycosi\n",
              "                  ...             \n",
              "102                    file situat\n",
              "103                  neg treatment\n",
              "104    neg treatment result situat\n",
              "105                        histori\n",
              "106          histori result situat\n",
              "Name: sentence, Length: 72, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "ABCZbGNEvxHl",
        "outputId": "7a70731a-f8c1-47f7-d0e7-7b21af307bc9"
      },
      "source": [
        "case['sentence'].to_csv(index= False)     #to remove the header write header=False"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sentence\\n5 all 740\\nalabama\\nadam\\nmanner\\nsycosi\\nwrit error sumter\\nwest headnot\\n1\\nchattel mortgag\\ncrop\\n4 case cite headnot\\ncreditor\\nprioriti\\n5 case cite headnot\\nattorney law\\nopinion\\ndissent opinion\\nsituat\\ndocument\\n2019 thomson claim origin u govern work\\nbite 9\\ntreatment\\ntitl\\ndate\\ntype\\ndepth\\nheadnot\\n1 hooker armi\\ndec\\ngrover convers cotton citi montgomeri john cunningham\\njan 1872\\n3 gibb manner\\nbanish wage exempt citi montgomeri john cunningham\\njan 1871\\n4 mckenzi ampl\\ntrial right properti cotton hale\\njan 1858\\n5 evan later\\nerror autauga\\n1852\\n6 dewey woman\\n1857\\nmention\\n7 tree\\ngrover convers three bale cotton wm l whitlow\\nnov 1880\\nmention\\nedward thompson\\nmay 1887\\n9 grow crop subject levi seizur attach execut\\n103 all 464\\n1936\\nall\\ntabl author 3\\ntreatment\\nrefer titl\\ntype\\ndepth\\nquot\\npage number\\nmention\\n1 austin\\nperson hayfield\\nwrit error tuskaloosa\\nmention\\n3 stewart doughi\\nfile\\nfile situat\\nneg treatment\\nneg treatment result situat\\nhistori\\nhistori result situat\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu4NoMUGDItK"
      },
      "source": [
        "case['sentence'].to_csv('excercise4.csv',index=False)   #to give the name to the file"
      ],
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vinNZr9MLLNs"
      },
      "source": [
        "#to give the path to save the file\r\n",
        "case['sentence'].to_csv(r'C:\\Users\\AZ\\Desktop\\A Data Science- Spring 2021\\INFO 5731\\Assignments-Data\\excercise4.csv',index = False)\r\n"
      ],
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggNrD_H5M7Rk"
      },
      "source": [
        "###1.4 Advance Text Processing\r\n",
        "###Calculate the term frequency of all the terms. Print out top 10 1-gram, top 10 2-grams, and top 10 3-grams terms as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "xAvD-8U5M6cS",
        "outputId": "56691189-1c15-476d-b61f-b2f716d36e14"
      },
      "source": [
        "###Calculate the term frequency of all the terms.\r\n",
        "tf1=(case['sentence']).apply(lambda x: pd.value_counts(x.split(' '))).sum(axis = 0).reset_index()\r\n",
        "tf1.columns = ['words','tf']\r\n",
        "tf1"
      ],
      "execution_count": 430,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>tf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>all</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>740</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>alabama</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adam</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>stewart</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>file</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>neg</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>result</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>histori</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>113 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       words   tf\n",
              "0          5  3.0\n",
              "1        all  3.0\n",
              "2        740  1.0\n",
              "3    alabama  1.0\n",
              "4       adam  1.0\n",
              "..       ...  ...\n",
              "108  stewart  1.0\n",
              "109     file  2.0\n",
              "110      neg  2.0\n",
              "111   result  2.0\n",
              "112  histori  2.0\n",
              "\n",
              "[113 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 430
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhdj8OB-P-XJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA5hdSIlQTzX"
      },
      "source": [
        "###Print out top 10 1-gram, top 10 2-grams, and top 10 3-grams terms as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XxW7oWrXW-D"
      },
      "source": [
        "from itertools import chain"
      ],
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyDqwDDRXWXz",
        "outputId": "8a618745-9771-45d4-8698-1bd0662a1011"
      },
      "source": [
        "#Print out top 10 1-gram\r\n",
        "def find_ngrams(input_list ,n):\r\n",
        "  return list(zip(*[input_list[i:] for i in range(n)]))\r\n",
        "case['monograms'] = case['sentence'].map(lambda x: find_ngrams(x.split(' '),1))\r\n",
        "case['sentence'].head(10)\r\n",
        "monograms = case['monograms'].tolist()\r\n",
        "monograms = list (chain(*monograms))\r\n",
        "monograms = [x for x in monograms]\r\n",
        "monogram_counts = Counter(monograms)\r\n",
        "monogram_counts.most_common(10)\r\n"
      ],
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('headnot',), 4),\n",
              " (('situat',), 4),\n",
              " (('treatment',), 4),\n",
              " (('mention',), 4),\n",
              " (('5',), 3),\n",
              " (('all',), 3),\n",
              " (('error',), 3),\n",
              " (('1',), 3),\n",
              " (('cotton',), 3),\n",
              " (('jan',), 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 492
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGYByQCpM6hK",
        "outputId": "e84aefe6-1da5-4541-bc66-b2b446686684"
      },
      "source": [
        "#Print out top 10 2-gram\r\n",
        "\r\n",
        "def find_ngrams(input_list ,n):\r\n",
        "  return list(zip(*[input_list[i:] for i in range(n)]))\r\n",
        "case['bigrams'] = case['sentence'].map(lambda x: find_ngrams(x.split(' '),2))\r\n",
        "case['sentence'].head(10)\r\n",
        "bigrams = case['bigrams'].tolist()\r\n",
        "bigrams = list (chain(*bigrams))\r\n",
        "bigrams = [(x , y) for x, y in bigrams]\r\n",
        "bigram_counts = Counter(bigrams)\r\n",
        "bigram_counts.most_common(10)"
      ],
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('writ', 'error'), 2),\n",
              " (('case', 'cite'), 2),\n",
              " (('cite', 'headnot'), 2),\n",
              " (('grover', 'convers'), 2),\n",
              " (('citi', 'montgomeri'), 2),\n",
              " (('montgomeri', 'john'), 2),\n",
              " (('john', 'cunningham'), 2),\n",
              " (('neg', 'treatment'), 2),\n",
              " (('result', 'situat'), 2),\n",
              " (('5', 'all'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 499
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI23RwWOLLXb",
        "outputId": "f3152364-02ba-4fdf-82af-ee5c9c84b45c"
      },
      "source": [
        "##Print out top 10 3-gram\r\n",
        "def find_ngrams(input_list ,n):\r\n",
        "  return list(zip(*[input_list[i:] for i in range(n)]))\r\n",
        "case['trigrams'] = case['sentence'].map(lambda x: find_ngrams(x.split(' '),3))\r\n",
        "case['sentence'].head(10)\r\n",
        "trigrams = case['trigrams'].tolist()\r\n",
        "trigrams = list (chain(*trigrams))\r\n",
        "trigrams = [(x,y,z) for x,y,z in trigrams]\r\n",
        "trigram_counts = Counter(trigrams)\r\n",
        "trigram_counts.most_common(10)"
      ],
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('case', 'cite', 'headnot'), 2),\n",
              " (('citi', 'montgomeri', 'john'), 2),\n",
              " (('montgomeri', 'john', 'cunningham'), 2),\n",
              " (('5', 'all', '740'), 1),\n",
              " (('writ', 'error', 'sumter'), 1),\n",
              " (('4', 'case', 'cite'), 1),\n",
              " (('5', 'case', 'cite'), 1),\n",
              " (('2019', 'thomson', 'claim'), 1),\n",
              " (('thomson', 'claim', 'origin'), 1),\n",
              " (('claim', 'origin', 'u'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydciPUVALLff"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBiC4E_kefvV"
      },
      "source": [
        "# 2. Python Regular Expression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1QJ-UwCenvN"
      },
      "source": [
        "## 2.1 Write a Python program to remove leading zeros from an IP address. (4 points)\n",
        "\n",
        "ip = \"260.08.094.109\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSv6fVhOfFmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137b9182-fc76-4d02-aab2-2851f8b757e7"
      },
      "source": [
        "# one way to remove leading zeros from ip address\n",
        "\n",
        "import re\n",
        "ip = \"260.08.094.109\"\n",
        "string = re.sub('\\.[0]*','.',ip)\n",
        "print(string)\n",
        "\n",
        "\n"
      ],
      "execution_count": 605,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "260.8.94.109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8CGl-k5b5Bn",
        "outputId": "d8867015-e022-4a61-b921-ef3cb5444a08"
      },
      "source": [
        "#another way to remove the leading zeros from ip address\r\n",
        "def removeZeros(ip):\r\n",
        "  ip_address = '.'.join([str(int(i)) for i in ip.split('.')])\r\n",
        "  return ip_address;\r\n",
        "ip=\"260.08.094.109\"\r\n",
        "print(removeZeros(ip))"
      ],
      "execution_count": 606,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "260.8.94.109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXRjaHzrfKAy"
      },
      "source": [
        "## 2.2 Write a Python Program to extract all the years from the following sentence. (4 points)\n",
        "\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdJpDx9gjbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9901424f-1bfe-43f5-a891-7d311ee71cc2"
      },
      "source": [
        "\r\n",
        "import re\r\n",
        "import datetime\r\n",
        "from datetime import date\r\n",
        "from dateutil.parser import parse\r\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, \\\r\n",
        "Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged \\\r\n",
        "from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\"\r\n",
        "all_years= re.findall(r'\\d{4}', sentence)\r\n",
        "print(all_years)\r\n",
        "\r\n"
      ],
      "execution_count": 626,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2010', '1000', '2010', '2019']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1IDKe8NymJU",
        "outputId": "afe7b1cf-2424-4d0a-abc0-bb83ca8c7a21"
      },
      "source": [
        "import re\r\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, \\\r\n",
        "Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged \\\r\n",
        "from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\"\r\n",
        "def all_years(sentence):\r\n",
        "  return re.findall(r'/(\\d{4})/(\\d{})/(\\d{})/',sentence)\r\n",
        "print(all_years(sentence))"
      ],
      "execution_count": 630,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIHIM-EM2xVz",
        "outputId": "306473c0-a242-4472-d6f8-7f45816aade7"
      },
      "source": [
        "!pip install date_extractor\r\n"
      ],
      "execution_count": 594,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: date_extractor in /usr/local/lib/python3.6/dist-packages (5.1.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from date_extractor) (2018.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from date_extractor) (2019.12.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgH_bxiz3bEo",
        "outputId": "0ab09ce0-e120-42ab-9d10-1dc2c4f67cc6"
      },
      "source": [
        "import date_extractor\r\n",
        "from date_extractor import extract_dates\r\n",
        "sentence = \"The 2010s were a dramatic decade, filled with ups and downs, more than 1000 stroies have happened. As the decade comes to a close, \\\r\n",
        "Insider took a look back at some of the biggest headline-grabbing stories, from 2010 to 2019. The result was 119 news stories that ranged \\\r\n",
        "from the heartwarming rescue of a Thai boys' soccer team from a flooded cave to the divisive election of President Donald Trump.\"\r\n",
        "dates = extract_dates(sentence)\r\n",
        "#date, precision = extract_date(sentence, return_precision = True)\r\n",
        "dates"
      ],
      "execution_count": 615,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[datetime.datetime(2010, 1, 1, 0, 0, tzinfo=<UTC>),\n",
              " datetime.datetime(2010, 1, 1, 0, 0, tzinfo=<UTC>),\n",
              " datetime.datetime(2019, 1, 1, 0, 0, tzinfo=<UTC>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 615
        }
      ]
    }
  ]
}
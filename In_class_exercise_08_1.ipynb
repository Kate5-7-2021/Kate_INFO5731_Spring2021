{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In_class_exercise_08-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kate5-7-2021/Kate_INFO5731_Spring2021/blob/main/In_class_exercise_08_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odudo4LSq9Ja"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 3/30/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj1PsnYtq9Jg"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf8TNcrfq9Ji"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogv9QTQHq9Ji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "e704f3c5-13dd-4540-cf6a-e7ec59f6fd09"
      },
      "source": [
        "import csv        # I redue the assignment 2 & 3 to get the new dataset because I think in the previous dataset all my data were repeated\n",
        "import pandas as pd     # This is a new link for my new csv file\n",
        "                        # https://github.com/Kate5-7-2021/Kate_INFO5731_Spring2021/blob/main/results-final.csv\n",
        "df = pd.read_csv('/content/results-final.csv')\n",
        "df\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document_id</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>bwho drtedro resignnl dec wechat group publish...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bsenatorhagerti wuhancoronaviru spread world t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>bjuliensorel chainhomotopi thelogankyl busi xf...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>bdrmadej i encourag everyon get vaccin necessa...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bchainhomotopi juliensorel thelogankyl busi xf...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>123</td>\n",
              "      <td>bswami you show understand civiliz issu herenn...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>124</td>\n",
              "      <td>bglobaltimesnew thatxexx want put ccp dog cage...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>125</td>\n",
              "      <td>btypediabet final ad massachusettsxexx list el...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>btelglobalhealth sneweyi good luck california ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>127</td>\n",
              "      <td>buk u criticis who covid report accus china wi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     document_id                                         clean_text sentiment\n",
              "0              0  bwho drtedro resignnl dec wechat group publish...   neutral\n",
              "1              1  bsenatorhagerti wuhancoronaviru spread world t...  positive\n",
              "2              2  bjuliensorel chainhomotopi thelogankyl busi xf...   neutral\n",
              "3              3  bdrmadej i encourag everyon get vaccin necessa...  positive\n",
              "4              4  bchainhomotopi juliensorel thelogankyl busi xf...   neutral\n",
              "..           ...                                                ...       ...\n",
              "123          123  bswami you show understand civiliz issu herenn...   neutral\n",
              "124          124  bglobaltimesnew thatxexx want put ccp dog cage...  negative\n",
              "125          125  btypediabet final ad massachusettsxexx list el...  positive\n",
              "126          126  btelglobalhealth sneweyi good luck california ...  negative\n",
              "127          127  buk u criticis who covid report accus china wi...  negative\n",
              "\n",
              "[128 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdvqiPU4iD9-"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWzQx8SVmYBX",
        "outputId": "fa53fae1-d7f7-4579-e92c-273d65a3ebf7"
      },
      "source": [
        "!pip install polyglot"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polyglot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/98/e24e2489114c5112b083714277204d92d372f5bbe00d5507acf40370edb9/polyglot-16.7.4.tar.gz (126kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 22.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 112kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 10.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52557 sha256=e51aceea7860042f0a85461909e1befa42b82215da628b32766361f12f244400\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/91/ef/f1369fdc1203b0a9347d4b24f149b83a305f39ab047986d9da\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhisaNQMo4Ks",
        "outputId": "5e2b80e2-f25f-40f4-a92d-d5a061ce07c4"
      },
      "source": [
        "!pip install pyicu"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyicu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/46/fa08c8efae2951e67681ec24319f789fc1a74e2096dd74373e34c79319de/PyICU-2.6.tar.gz (233kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20kB 10.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 143kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 153kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 163kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 174kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 184kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 194kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 204kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 215kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 225kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 7.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.6-cp37-cp37m-linux_x86_64.whl size=1306402 sha256=071356cdaac519b366a7953b70afb26b8f3e7fe5efb5ce8a2ba76213ddba2d8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/21/2f/1c91831e8a93537ab21f6b4b935781b681104635fdb0315791\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYXkThnqpKyV",
        "outputId": "5001b61b-62ff-4a80-95af-65a8a2c2861c"
      },
      "source": [
        "! pip install pycld2"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 104kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834263 sha256=78e2067423c845fb96336f4f621e3c3c5a9133cf025a8d77548b8ee236401104\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhYoNtdKiEB8",
        "outputId": "5d217cd2-9b6a-453a-de3d-13897ee511ec"
      },
      "source": [
        "from polyglot.downloader import downloader             #this code shows all languages that polyglot has polarity lexicons for them\n",
        "print(downloader.supported_languages_table(\"sentiment2\", 3))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1. Kapampangan                2. Italian                    3. Upper Sorbian            \n",
            "  4. Sakha                      5. Hindi                      6. French                   \n",
            "  7. Spanish; Castilian         8. Vietnamese                 9. Arabic                   \n",
            " 10. Macedonian                11. Pashto, Pushto            12. Bosnian-Croatian-Serbian \n",
            " 13. Egyptian Arabic           14. Norwegian Nynorsk         15. Sundanese                \n",
            " 16. Sicilian                  17. Azerbaijani               18. Bulgarian                \n",
            " 19. Yoruba                    20. Tajik                     21. Georgian                 \n",
            " 22. Tatar                     23. Galician                  24. Malagasy                 \n",
            " 25. Uighur, Uyghur            26. Amharic                   27. Venetian                 \n",
            " 28. Yiddish                   29. Norwegian                 30. Alemannic                \n",
            " 31. Estonian                  32. West Flemish              33. Divehi; Dhivehi; Mald... \n",
            " 34. Japanese                  35. Ilokano                   36. Haitian; Haitian Creole  \n",
            " 37. Belarusian                38. Greek, Modern             39. Ossetian, Ossetic        \n",
            " 40. Welsh                     41. Malayalam                 42. Albanian                 \n",
            " 43. Marathi (Marāṭhī)         44. Armenian                  45. Slovene                  \n",
            " 46. Korean                    47. Breton                    48. Irish                    \n",
            " 49. Luxembourgish, Letzeb...  50. Bengali                   51. Serbian                  \n",
            " 52. Fiji Hindi                53. Javanese                  54. Finnish                  \n",
            " 55. Gan Chinese               56. Kirghiz, Kyrgyz           57. Catalan; Valencian       \n",
            " 58. Quechua                   59. Croatian                  60. Dutch                    \n",
            " 61. Swedish                   62. Ido                       63. Tagalog                  \n",
            " 64. Sanskrit (Saṁskṛta)       65. Piedmontese language      66. Asturian                 \n",
            " 67. Danish                    68. Cebuano                   69. Western Frisian          \n",
            " 70. Kannada                   71. Scots                     72. Maltese                  \n",
            " 73. Swahili                   74. Limburgish, Limburgan...  75. Waray-Waray              \n",
            " 76. Lombard language          77. Uzbek                     78. Kurdish                  \n",
            " 79. Latvian                   80. Burmese                   81. Aragonese                \n",
            " 82. Volapük                   83. Northern Sami             84. Faroese                  \n",
            " 85. Kazakh                    86. Telugu                    87. Ukrainian                \n",
            " 88. Assamese                  89. Chuvash                   90. Silesian                 \n",
            " 91. Turkmen                   92. Romanian, Moldavian, ...  93. Persian                  \n",
            " 94. Tibetan Standard, Tib...  95. Latin                     96. Slovak                   \n",
            " 97. Sinhala, Sinhalese        98. Bavarian                  99. Icelandic                \n",
            "100. Mongolian                101. Walloon                  102. Portuguese               \n",
            "103. Urdu                     104. Gujarati                 105. Manx                     \n",
            "106. Tamil                    107. Chinese Word             108. Khmer                    \n",
            "109. English                  110. Malay                    111. Chechen                  \n",
            "112. Bishnupriya Manipuri     113. Afrikaans                114. Basque                   \n",
            "115. Polish                   116. German                   117. Esperanto                \n",
            "118. Indonesian               119. Occitan                  120. Chinese                  \n",
            "121. Czech                    122. Hebrew (modern)          123. Romansh                  \n",
            "124. Lithuanian               125. Turkish                  126. Nepali                   \n",
            "127. Bosnian                  128. Interlingua              129. Zazaki                   \n",
            "130. Oriya                    131. Hungarian                132. Scottish Gaelic; Gaelic  \n",
            "133. Bashkir                  134. Thai                     135. Panjabi, Punjabi         \n",
            "136. Russian                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWiW1c4Fubj-",
        "outputId": "7870831e-bf04-434d-e452-012b540f7f1c"
      },
      "source": [
        "! pip install morfessor"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.7/dist-packages (2.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Ou8I9yiEFT"
      },
      "source": [
        "from polyglot.text import Text\n",
        "\n",
        "text = Text(\"bswami you show understand civiliz issu herenn\")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn_QHViliEIY",
        "outputId": "f207bf51-e5a3-476e-a621-43bbb95f3375"
      },
      "source": [
        "%%bash\n",
        "polyglot download sentiment2.en"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package sentiment2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data]   Package sentiment2.en is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJtLqAH7iELi",
        "outputId": "421c208c-1751-471b-e0e0-cba1d5386029"
      },
      "source": [
        "print(\"{:<16}{}\".format(\"Word\", \"Polarity\")+\"\\n\"+\"-\"*30)      #to test the polarity of the text\n",
        "for w in text.words:\n",
        "    print(\"{:<16}{:>2}\".format(w, w.polarity))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word            Polarity\n",
            "------------------------------\n",
            "bswami           0\n",
            "you              0\n",
            "show             0\n",
            "understand       0\n",
            "civiliz          0\n",
            "issu             0\n",
            "herenn           0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqMrFdpJRYkg"
      },
      "source": [
        "from textblob import TextBlob\n",
        "df['clean_text'] = df['clean_text'].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJESls09JUTU",
        "outputId": "7b02599e-2663-4362-93c9-28c301e30f17"
      },
      "source": [
        "df.sentiment.value_counts()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    54\n",
              "negative    50\n",
              "neutral     23\n",
              "neagtive     1\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2xPx2wSiEOm",
        "outputId": "d41e667b-2271-4415-a732-a5cf556b8046"
      },
      "source": [
        "from polyglot.text import Text\n",
        "s_words = []\n",
        "for line in df['clean_text']:\n",
        "  text = Text(line)\n",
        "  for w in text.words:\n",
        "      s_words.append(w)\n",
        "print(s_words)\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n",
            "Detector is not able to detect the language reliably.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['who', 'drtedro', 'resigned', 'dec', 'what', 'group', 'publish', 'present', 'sarslik', 'virusnjan', 'china', 'tell', 'whoxexxa', 'httpstcoaacuuwjmk', 'bsenatorhagerti', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'concealxexxa', 'httpstcoyphehfn', 'bjuliensorel', 'chainhomotopi', 'thelogankyl', 'busy', 'xfxfxx', 'due', 'sad', 'i', 'told', 'one', 'hashtag', 'wuhancoronaviru', 'bdrmadej', 'i', 'encourage', 'everyone', 'get', 'vaccine', 'necessary', 'consider', 'care', 'potentixexxa', 'httpstcowzlpvsa', 'bchainhomotopi', 'juliensorel', 'thelogankyl', 'busy', 'xfxfxx', 'seem', 'guy', 'donxexxt', 'get', 'i', 'told', 'guy', 'alreadyxexxa', 'httpstcowlkphh', 'the', 'end', 'week', 'reduce', 'burden', 'alley', 'virus', 'american', 'hospital', 'week', 'overduexexxa', 'httpstcouyvobizhh', 'bdelglenndavi', 'the', 'two', 'week', 'suppose', 'end', 'one', 'year', 'ago', 'now', 'told', 'ostracizedxexxa', 'httpstcokyiaqtsxh', 'bglobaltimesnew', 'xexxctechn', 'testsxexxd', 'xfxfxxxfxfxxxfxfxx', 'up', 'sure', 'plea', 'cooper', 'cure', 'disease', 'mind', 'cap', 'plaxexxa', 'httpstcoikyzxvwxfq', 'bjuliensorel', 'chainhomotopi', 'thelogankyl', 'busy', 'you', 'guy', 'still', 'go', 'shit', 'xfxfxaxaxfxfxfxbbxexxdxexxxefxbxfxfxfxx', 'look', 'guy', 'atxexxa', 'httpstcoulhzitetn', 'best', 'wsjopinion', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'conceaxexxa', 'httpstcorfjudajaqc', 'bsenjoniernst', 'who', 'siouxlandnew', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'toxexxa', 'httpstcogdiqpmbvzq', 'byahoonew', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'he', 'ixexxa', 'httpstcoorsiawyum', 'btriciayeoh', 'we', 'want', 'live', 'perfect', 'world', 'perfect', 'situate', 'smooth', 'sail', 'without', 'wuhancoronaviru', 'wherxexxa', 'httpstcoqfunhiljgl', 'bdavidaltonhl', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryedxexxa', 'httpstcoxzafpi', 'bspeakerpelosi', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryexexxa', 'httpstcoqdagtewef', 'bguardianau', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryedxexxa', 'httpstcomnbvmogod', 'bchannelnewsasia', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destorxexxa', 'httpstcolttth', 'bnikkeiasia', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'bxexxa', 'httpstcompscajzefh', 'bin', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'byxexxa', 'httpstcobrfcbzcw', 'bguardianworld', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'nowxexxa', 'httpstcodduwbwgsb', 'bindepend', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'hkxexxa', 'httpstcovymfuulqm', 'bfreedomhous', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'hxexxa', 'httpstcodqjzbadkrk', 'bfinancialtim', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'nowxexxa', 'httpstcofgktavfm', 'bfinancialtim', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'desxexxa', 'httpstcoqwetxfsgp', 'better', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'he', 'isxexxa', 'httpstcoizhynmfu', 'bipacglob', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryxexxa', 'httpstcoesgwbji', 'bnadiawhittomemp', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'noxexxa', 'httpstcozsjuhfwgm', 'beasiamediahub', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destxexxa', 'httpstcobcpvtebm', 'bjeppekofod', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryxexxa', 'httpstcoteyujegj', 'bsarahchampionmp', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'noxexxa', 'httpstcojlqeqmdqc', 'bsecblinken', 'cap', 'comply', 'agreement', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracyxexxa', 'httpstcoqkpebmehct', 'bglobaltimesnew', 'disgust', 'human', 'china', 'spread', 'wuhancoronaviru', 'world', 'act', 'xfxfxaxaxexxa', 'httpstcouvahsavi', 'bglobaltimesnew', 'china', 'caught', 'part', 'who', 'claim', 'china', 'withheld', 'raw', 'datannwuhanvirusxexxa', 'httpstcorxlledkvk', 'bglobaltimesnew', 'who', 'start', 'pandemicnnwuhanviru', 'wuhancoronaviru', 'china', 'chinaviru', 'chinaliedpeopledi', 'bglobaltimesnew', 'who', 'who', 'clearly', 'said', 'china', 'withheld', 'raw', 'data', 'what', 'hidennwuhanvirusxexxa', 'httpstcohpnncaac', 'hear', 'hear', 'wuhancoronaviru', 'wuhanlab', 'nov', 'sarco', 'who', 'httpstcocmsjjzdci', 'bcbseveningnew', 'who', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'coxexxa', 'httpstcoqsxbjccr', 'byahoonew', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'concealmentxexxa', 'httpstcoojptkobm', 'brepgallagh', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'concealmexexxa', 'httpstcounbxcoevx', 'bimseano', 'they', 'call', 'all', 'death', 'wuhancoronaviru', 'include', 'car', 'motorcycl', 'vehicle', 'acid', 'victim', 'both', 'joebiden', 'author', 'million', 'u', 'taxpayer', 'who', 'drtedro', 'complete', 'cave', 'uncooperxexxa', 'httpstcorgufyvtq', 'swamp', 'you', 'show', 'understand', 'civil', 'issue', 'herennthes', 'brain', 'country', 'try', 'toxexxa', 'httpstcokgbiypr', 'bglobaltimesnew', 'thatxexx', 'want', 'put', 'cap', 'dog', 'cage', 'xfxfxxxfxfxxxfxfxx', 'cap', 'kill', 'million', 'spreadixexxa', 'httpstcotzlkglrc', 'btypediabet', 'final', 'ad', 'massachusettsxexx', 'list', 'fig', 'media', 'conduct', 'stage', 'thexexxa', 'httpstcopprawotc', 'btelglobalhealth', 'sneweyi', 'good', 'luck', 'california', 'us', 'i', 'sure', 'hope', 'country', 'prevail', 'china', 'wuhancoronaviru', 'but', 'u', 'criticism', 'who', 'could', 'report', 'accuse', 'china', 'withhold', 'data', 'wuhancoronaviru', 'httpstcoijaddfla', 'bglobaltimesnew', 'so', 'who', 'admit', 'china', 'didn', 'share', 'raw', 'data', 'clearly', 'attempt', 'hide', 'fact', 'wuhanvirusxexxa', 'httpstcontvmpyrxa', 'bmarcorubio', 'who', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'conceaxexxa', 'httpstcorpiepjdlb', 'bfoxfriendsfirst', 'repkatcammack', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'ccpxexxa', 'httpstcovdkrepq', 'brepkatcammack', 'who', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'conxexxa', 'httpstcojubspb', 'breparrington', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'concealmexexxa', 'httpstcorihzubqgb', 'the', 'who', 'investing', 'origin', 'sarco', 'disappoint', 'wuhancoronaviru', 'wncovxexxa', 'httpstcoraxfdryxwx', 'bwuhancoronaviru', 'ncovidnnthi', 'omit', 'world', 'need', 'new', 'vaccine', 'fight', 'coronaviru', 'year', 'say', 'majxexxa', 'httpstcotiuqzpaifk', 'bjohnbarron', 'modern', 'say', 'safety', 'wuhancoronaviru', 'vaccine', 'uncertain', 'bjohnbarron', 'modern', 'say', 'safety', 'wuhancoronaviru', 'vaccine', 'uncertain', 'bglobaltimesnew', 'itxexx', 'hope', 'world', 'body', 'acknowledge', 'already', 'know', 'in', 'wuhancoronaviru', 'spread', 'bxexxa', 'httpstcolzmorkcub', 'bthomasewood', 'is', 'dick', 'sport', 'good', 'plan', 'autoclave', 'merchandise', 'that', 'return', 'store', 'thatsxexxa', 'httpstcoloslrbi', 'bbridgebum', 'thomasewood', 'i', 'also', 'seen', 'public', 'library', 'virtuesign', 'claim', 'quarante', 'returnedxexxa', 'httpstcoxyzqcnipi', 'bglobaltimesnew', 'these', 'gift', 'donate', 'chinesecommunistparti', 'spare', 'chance', 'humble', 'countxexxa', 'httpstcofrgwtdremi', 'they', 'take', 'china', 'word', 'china', 'word', 'xfxfxxxfxfxxif', 'that', 'want', 'name', 'inquiryxexxa', 'httpstcosnuxnwbirm', 'bdrbonniehenri', 'adriandix', 'may', 'launch', 'new', 'crushingrestrict', 'britishcolumbia', 'nnwhi', 'variant', 'txexxa', 'httpstcolzraeufg', 'i', 'guess', 'lesleyrstahl', 'minute', 'final', 'onboardntoo', 'little', 'late', 'usnwuhancoronaviru', 'httpstcohdxqkiaq', 'yeah', 'sure', 'joint', 'whochina', 'study', 'origin', 'could', 'say', 'transmit', 'virus', 'bat', 'huxexxa', 'httpstcolgleafiplm', 'busy', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'conceal', 'oxexxa', 'httpstcockfldnzwc', 'bglobaltimesnew', 'sinovac', 'sinopharm', 'poor', 'quality', 'vaccine', 'prove', 'low', 'efficacy', 'rate', 'bexexxa', 'httpstcobyrgqatk', 'bthesun', 'now', 'cap', 'enemy', 'world', 'freedom', 'democracy', 'source', 'harm', 'plea', 'decoupl', 'axexxa', 'httpstcohmxsqhevg', 'bcatturd', 'the', 'wuhancoronaviru', 'hit', 'florida', 'soon', 'it', 'smart', 'virus', 'know', 'go', 'long', 'wait', 'forxexxa', 'httpstcoeandmdivd', 'opinion', 'claradfmarqu', 'seven', 'people', 'die', 'usedxcxa', 'sinovac', 'vaccine', 'also', 'necessary', 'stop', 'but', 'nowxexxa', 'httpstcodyaduss', 'expert', 'david', 'ashes', 'say', 'lab', 'leak', 'explain', 'could', 'wuhancoronaviru', 'source', 'httpstcotdrjuvwi', 'via', 'mailonlin', 'bsmitaprakash', 'the', 'dog', 'proved', 'china', 'commit', 'deadly', 'pathogenic', 'turn', 'wuhancoronaviru', 'increase', 'pace', 'vaccine', 'drive', 'million', 'vaccine', 'shot', 'day', 'would', 'idealnwuhancoronavirusxexxa', 'httpstcopdhvjqr', 'bcnannadhurai', 'sumanthraman', 'mithran', 'aiadmkoffici', 'arivalayam', 'who', 'abuse', 'you', 'free', 'vote', 'xfxfxxb', 'paxexxa', 'httpstcojidunlha', 'bglobaltimesnew', 'now', 'even', 'call', 'african', 'virus', 'found', 'china', 'it', 'renal', 'china', 'swine', 'fever', 'xxxi', 'httpstcoqtvafqo', 'b', 'minute', 'sunday', 'march', 'might', 'level', 'origin', 'wuhancoronaviru', 'did', 'comexexxa', 'httpstcolhqoaeef', 'solomon', 'due', 'twitter', 'some', 'million', 'miss', 'mobile', 'phone', 'found', 'what', 'crematorium', 'xfxfxxaxfxfxxbpeopl', 'whoxexxa', 'httpstcohxacyrxsbi', 'bsubnobodi', 'flmomfreedom', 'it', 'wuhancoronaviru', 'peri', 'dishnnright', 'fever', 'got', 'load', 'planxexxa', 'httpstcoltdxlfdavr', 'bcongratul', 'american', 'dr', 'levi', 'assist', 'health', 'secretarynnthi', 'transcend', 'person', 'movedxexxa', 'httpstcoqoewpplta', 'bdisclosetv', 'jillcoltonfre', 'he', 'must', 'learn', 'wuhancoronaviru', 'i', 'keep', 'notice', 'thatxexxa', 'httpstcocveebowh', 'busy', 'in', 'postpandem', 'time', 'people', 'ask', 'wuhancoronaviru', 'come', 'bdrericd', 'best', 'vaccine', 'wuhancoronaviru', 'india', 'made', 'cocain', 'le', 'expense', 'plus', 'store', 'le', 'temperature', 'utero', 'your', 'firednxexcxxexacxnhttpstconkacosldncoronaviruschina', 'pndahuggerncoronachan', 'coronachan', 'xexxbxexxadxexxaxexxaxexxxexxxexxa', 'httpstcoklgkjsgsn', 'bykov', 'zigmanfreud', 'teacher', 'get', 'as', 'back', 'classroom', 'like', 'u', 'workinxexxa', 'httpstconfazueq', 'who', 'drtedro', 'resigned', 'dec', 'what', 'group', 'publish', 'present', 'sarslik', 'virusnjan', 'china', 'tell', 'whoxexxa', 'httpstcoaacuuwjmk', 'bsenatorhagerti', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'concealxexxa', 'httpstcoyphehfn', 'bjuliensorel', 'chainhomotopi', 'thelogankyl', 'busy', 'xfxfxx', 'due', 'sad', 'i', 'told', 'one', 'hashtag', 'wuhancoronaviru', 'bdrmadej', 'i', 'encourage', 'everyone', 'get', 'vaccine', 'necessary', 'consider', 'care', 'potentixexxa', 'httpstcowzlpvsa', 'bchainhomotopi', 'juliensorel', 'thelogankyl', 'busy', 'xfxfxx', 'seem', 'guy', 'donxexxt', 'get', 'i', 'told', 'guy', 'alreadyxexxa', 'httpstcowlkphh', 'the', 'end', 'week', 'reduce', 'burden', 'alley', 'virus', 'american', 'hospital', 'week', 'overduexexxa', 'httpstcouyvobizhh', 'bdelglenndavi', 'the', 'two', 'week', 'suppose', 'end', 'one', 'year', 'ago', 'now', 'told', 'ostracizedxexxa', 'httpstcokyiaqtsxh', 'bglobaltimesnew', 'xexxctechn', 'testsxexxd', 'xfxfxxxfxfxxxfxfxx', 'up', 'sure', 'plea', 'cooper', 'cure', 'disease', 'mind', 'cap', 'plaxexxa', 'httpstcoikyzxvwxfq', 'bjuliensorel', 'chainhomotopi', 'thelogankyl', 'busy', 'you', 'guy', 'still', 'go', 'shit', 'xfxfxaxaxfxfxfxbbxexxdxexxxefxbxfxfxfxx', 'look', 'guy', 'atxexxa', 'httpstcoulhzitetn', 'best', 'wsjopinion', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'conceaxexxa', 'httpstcorfjudajaqc', 'bsenjoniernst', 'who', 'siouxlandnew', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'toxexxa', 'httpstcogdiqpmbvzq', 'byahoonew', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'he', 'ixexxa', 'httpstcoorsiawyum', 'btriciayeoh', 'we', 'want', 'live', 'perfect', 'world', 'perfect', 'situate', 'smooth', 'sail', 'without', 'wuhancoronaviru', 'wherxexxa', 'httpstcoqfunhiljgl', 'bdavidaltonhl', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryedxexxa', 'httpstcoxzafpi', 'bspeakerpelosi', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryexexxa', 'httpstcoqdagtewef', 'bguardianau', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryedxexxa', 'httpstcomnbvmogod', 'bchannelnewsasia', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destorxexxa', 'httpstcolttth', 'bnikkeiasia', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'bxexxa', 'httpstcompscajzefh', 'bin', 'proud', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'byxexxa', 'httpstcobrfcbzcw', 'bguardianworld', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'nowxexxa', 'httpstcodduwbwgsb', 'bindepend', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'hkxexxa', 'httpstcovymfuulqm', 'bfreedomhous', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'hxexxa', 'httpstcodqjzbadkrk', 'bfinancialtim', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'nowxexxa', 'httpstcofgktavfm', 'bfinancialtim', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'desxexxa', 'httpstcoqwetxfsgp', 'better', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'now', 'he', 'isxexxa', 'httpstcoizhynmfu', 'bipacglob', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryxexxa', 'httpstcoesgwbji', 'bnadiawhittomemp', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'noxexxa', 'httpstcozsjuhfwgm', 'beasiamediahub', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destxexxa', 'httpstcobcpvtebm', 'bjeppekofod', 'thank', 'much', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destoryxexxa', 'httpstcoteyujegj', 'bsarahchampionmp', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracy', 'he', 'destroy', 'cap', 'noxexxa', 'httpstcojlqeqmdqc', 'bsecblinken', 'cap', 'comply', 'agreement', 'onecountrytwosystemsisdeadnth', 'rule', 'law', 'freedom', 'democracyxexxa', 'httpstcoqkpebmehct', 'bglobaltimesnew', 'disgust', 'human', 'china', 'spread', 'wuhancoronaviru', 'world', 'act', 'xfxfxaxaxexxa', 'httpstcouvahsavi', 'bglobaltimesnew', 'china', 'caught', 'part', 'who', 'claim', 'china', 'withheld', 'raw', 'datannwuhanvirusxexxa', 'httpstcorxlledkvk', 'bglobaltimesnew', 'who', 'start', 'pandemicnnwuhanviru', 'wuhancoronaviru', 'china', 'chinaviru', 'chinaliedpeopledi', 'bglobaltimesnew', 'who', 'who', 'clearly', 'said', 'china', 'withheld', 'raw', 'data', 'what', 'hidennwuhanvirusxexxa', 'httpstcohpnncaac', 'hear', 'hear', 'wuhancoronaviru', 'wuhanlab', 'nov', 'sarco', 'who', 'httpstcocmsjjzdci', 'bcbseveningnew', 'who', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'coxexxa', 'httpstcoqsxbjccr', 'byahoonew', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'concealmentxexxa', 'httpstcoojptkobm', 'brepgallagh', 'wuhancoronaviru', 'spread', 'world', 'thank', 'who', 'help', 'cap', 'cap', 'concealmexexxa', 'httpstcounbxcoevx', 'bimseano', 'they', 'call', 'all', 'death', 'wuhancoronaviru', 'include', 'car', 'motorcycl', 'vehicle', 'acid', 'victim', 'both', 'joebiden', 'author', 'million', 'u', 'taxpayer', 'who', 'drtedro', 'complete', 'cave', 'uncooperxexxa', 'httpstcorgufyvtq', 'swamp', 'you', 'show', 'understand', 'civil', 'issue', 'herennthes', 'brain', 'country', 'try', 'toxexxa', 'httpstcokgbiypr', 'bglobaltimesnew', 'thatxexx', 'want', 'put', 'cap', 'dog', 'cage', 'xfxfxxxfxfxxxfxfxx', 'cap', 'kill', 'million', 'spreadixexxa', 'httpstcotzlkglrc', 'btypediabet', 'final', 'ad', 'massachusettsxexx', 'list', 'fig', 'media', 'conduct', 'stage', 'thexexxa', 'httpstcopprawotc', 'btelglobalhealth', 'sneweyi', 'good', 'luck', 'california', 'us', 'i', 'sure', 'hope', 'country', 'prevail', 'china', 'wuhancoronaviru', 'but', 'u', 'criticism', 'who', 'could', 'report', 'accuse', 'china', 'withhold', 'data', 'wuhancoronaviru', 'httpstcoijaddfla']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "--U7TTxKiERb",
        "outputId": "81f6f7b7-027f-4cfa-fd79-0a545b713911"
      },
      "source": [
        "from collections import Counter\n",
        "freq = Counter(s_words)\n",
        "df1 = pd.DataFrame(list(freq.most_common()), columns=['word', 'frequency'])\n",
        "df1.index = list(range(1, len(freq.most_common())+1))\n",
        "df1\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cap</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wuhancoronaviru</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>who</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>he</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>freedom</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>classroom</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>like</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>workinxexxa</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>httpstconfazueq</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>531 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                word  frequency\n",
              "1                cap         53\n",
              "2    wuhancoronaviru         45\n",
              "3                who         42\n",
              "4                 he         41\n",
              "5            freedom         39\n",
              "..               ...        ...\n",
              "527             back          1\n",
              "528        classroom          1\n",
              "529             like          1\n",
              "530      workinxexxa          1\n",
              "531  httpstconfazueq          1\n",
              "\n",
              "[531 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1OnLPrIiHn5"
      },
      "source": [
        "#(2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers.\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmxZJIP0l8b7"
      },
      "source": [
        "##**TextBlob Sentiment Identification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA8j7SwRISbP"
      },
      "source": [
        "for word in df['sentiment']:\n",
        "  \n",
        "  if word == 'positive':\n",
        "    encoded = 1\n",
        "  elif word == 'negative':\n",
        "    encoded = -1\n",
        "  elif word == 'neutral':\n",
        "    encode = 0\n",
        "\n",
        "s_real = []\n",
        "for word in df['sentiment']:\n",
        "   s_real.append(Encoder(word))\n"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Aph2H9AbISVk",
        "outputId": "cb3413c7-4faf-4341-890e-1b217f34b9c3"
      },
      "source": [
        "from textblob import TextBlob\n",
        "tb_s = []\n",
        "for line in df['clean_text']:\n",
        "  polarity = TextBlob(line).sentiment.polarity\n",
        "  if polarity > 0:\n",
        "    tb_s.append(1)\n",
        "  elif polarity < 0:\n",
        "    tb_s.append(-1)\n",
        "  elif polarity == 0.0:\n",
        "    tb_s.append(0)\n",
        "df2 = pd.DataFrame(list(zip(df['clean_text'], s_real, tb_s)), columns = ['clean_text', 'manual_polarity', 'tb_polarity'])\n",
        "df2\n"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>manual_polarity</th>\n",
              "      <th>tb_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>who drtedro resigned dec what group publish pr...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bsenatorhagerti wuhancoronaviru spread world t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bjuliensorel chainhomotopi thelogankyl busy xf...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bdrmadej i encourage everyone get vaccine nece...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bchainhomotopi juliensorel thelogankyl busy xf...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>swamp you show understand civil issue herennth...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>bglobaltimesnew thatxexx want put cap dog cage...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>btypediabet final ad massachusettsxexx list fi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>btelglobalhealth sneweyi good luck california ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>but u criticism who could report accuse china ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            clean_text  ...  tb_polarity\n",
              "0    who drtedro resigned dec what group publish pr...  ...            0\n",
              "1    bsenatorhagerti wuhancoronaviru spread world t...  ...            0\n",
              "2    bjuliensorel chainhomotopi thelogankyl busy xf...  ...           -1\n",
              "3    bdrmadej i encourage everyone get vaccine nece...  ...            0\n",
              "4    bchainhomotopi juliensorel thelogankyl busy xf...  ...            1\n",
              "..                                                 ...  ...          ...\n",
              "123  swamp you show understand civil issue herennth...  ...            0\n",
              "124  bglobaltimesnew thatxexx want put cap dog cage...  ...            0\n",
              "125  btypediabet final ad massachusettsxexx list fi...  ...            0\n",
              "126  btelglobalhealth sneweyi good luck california ...  ...            1\n",
              "127  but u criticism who could report accuse china ...  ...            0\n",
              "\n",
              "[128 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPNeMU95ISM4",
        "outputId": "8661b42a-2e59-4e8c-da84-d37817251c72"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "tb_accuracy = accuracy_score(df2['manual_polarity'], df2['tb_polarity'])*100\n",
        "tb_score = f1_score(df2['manual_polarity'], df2['tb_polarity'], average = 'macro')\n",
        "print(\"Accuracy of TextBlob is {0} and F1 Score is {1}\".format(tb_accuracy, tb_score))\n"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of TextBlob is 43.75 and F1 Score is 0.4251563251563251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVY7nTX6lrOQ"
      },
      "source": [
        "##**Vader Sentiment Identification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC5L1DAhIdmi",
        "outputId": "f673a779-df5e-4756-9159-32380b7f6dd3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "g5QFGXSVIdjW",
        "outputId": "1d2f4151-c4be-4afb-8525-eb4c4b590c6c"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "va = SentimentIntensityAnalyzer()\n",
        "va_s = []\n",
        "for line in df['clean_text']:\n",
        "  polarity = va.polarity_scores(line)['compound']\n",
        "  if polarity > 0:\n",
        "    va_s.append(1)\n",
        "  elif polarity < 0:\n",
        "    va_s.append(-1)\n",
        "  elif polarity == 0.0:\n",
        "    va_s.append(0)\n",
        "df3 = pd.DataFrame(list(zip(df['clean_text'], s_real , va_s)), columns = ['clean_text', 'manual_polarity', 'va_polarity'])\n",
        "df3\n"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>manual_polarity</th>\n",
              "      <th>va_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>who drtedro resigned dec what group publish pr...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bsenatorhagerti wuhancoronaviru spread world t...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bjuliensorel chainhomotopi thelogankyl busy xf...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bdrmadej i encourage everyone get vaccine nece...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bchainhomotopi juliensorel thelogankyl busy xf...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>swamp you show understand civil issue herennth...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>bglobaltimesnew thatxexx want put cap dog cage...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>btypediabet final ad massachusettsxexx list fi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>btelglobalhealth sneweyi good luck california ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>but u criticism who could report accuse china ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            clean_text  ...  va_polarity\n",
              "0    who drtedro resigned dec what group publish pr...  ...           -1\n",
              "1    bsenatorhagerti wuhancoronaviru spread world t...  ...            1\n",
              "2    bjuliensorel chainhomotopi thelogankyl busy xf...  ...           -1\n",
              "3    bdrmadej i encourage everyone get vaccine nece...  ...            1\n",
              "4    bchainhomotopi juliensorel thelogankyl busy xf...  ...            0\n",
              "..                                                 ...  ...          ...\n",
              "123  swamp you show understand civil issue herennth...  ...            0\n",
              "124  bglobaltimesnew thatxexx want put cap dog cage...  ...           -1\n",
              "125  btypediabet final ad massachusettsxexx list fi...  ...            0\n",
              "126  btelglobalhealth sneweyi good luck california ...  ...            1\n",
              "127  but u criticism who could report accuse china ...  ...           -1\n",
              "\n",
              "[128 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GaD7WBdIddA",
        "outputId": "34366bda-15dd-4a43-ef6d-5144ea4530ef"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "va_accuracy = accuracy_score(df3['manual_polarity'], df3['va_polarity'])*100\n",
        "va_f1_score = f1_score(df3['manual_polarity'], df3['va_polarity'], average = 'macro' )\n",
        "print(\"Accuracy of vader is {0} and F1 Score is {1}\".format(va_accuracy, va_f1_score))\n"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of vader is 61.71875 and F1 Score is 0.5864970313825276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q11ec1srrBkQ"
      },
      "source": [
        "##**SVM Sentiment Identification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M3H5OokISK_"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sO_wE_4ISHO"
      },
      "source": [
        "TFid_vectorizer = TfidfVectorizer(min_df = 5, max_df = 0.8, sublinear_tf = True, use_idf = True)\n",
        "\n",
        "Train_X, Test_X, Train_Y, Test_Y = train_test_split(df['clean_text'],df['sentiment'],test_size=0.33)\n",
        "Encode = LabelEncoder()\n",
        "Train_Y = Encode.fit_transform(Train_Y)\n",
        "Test_Y = Encode.fit_transform(Test_Y)\n",
        "Train_X_vec = TFid_vectorizer.fit_transform(Train_X)\n",
        "Test_X_vec = TFid_vectorizer.transform(Test_X)\n",
        "\n"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ycezrhMISEm",
        "outputId": "28fa56a2-30a7-4337-c05c-7dd0bdad749f"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "svm_model = svm.SVC(kernel='linear')\n",
        "svm_model.fit(Train_X_vec, Train_Y)\n",
        "predicted = svm_model.predict(Test_X_vec)\n",
        "output = classification_report(Test_Y, predicted, output_dict=True)\n",
        "output"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 17},\n",
              " '1': {'f1-score': 0.3783783783783784,\n",
              "  'precision': 0.25,\n",
              "  'recall': 0.7777777777777778,\n",
              "  'support': 9},\n",
              " '2': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 17},\n",
              " '3': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0, 'support': 0},\n",
              " 'accuracy': 0.16279069767441862,\n",
              " 'macro avg': {'f1-score': 0.0945945945945946,\n",
              "  'precision': 0.0625,\n",
              "  'recall': 0.19444444444444445,\n",
              "  'support': 43},\n",
              " 'weighted avg': {'f1-score': 0.07919547454431176,\n",
              "  'precision': 0.05232558139534884,\n",
              "  'recall': 0.16279069767441862,\n",
              "  'support': 43}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9ZkIzwH8Mbx"
      },
      "source": [
        "##**Results**\n",
        "#### TextBlob: Accuracy of TextBlob is 43.75 and F1 Score is 0.4251563251563251\n",
        "                                        \n",
        "#### Vader: Accuracy of vader is 61.71875 and F1 Score is 0.5864970313825276 \n",
        "\n",
        "#### SVM: Based on the above results of the SVM identification tools the value of the precision and recall both present and after each running time either by changing the min_df, max_df (for example changing the min_df to 4 or 6 and changing the max_df to 0.7 or 0.9) one can get different results for F1 score, min_df, max_df. However, in each try I got the F1 score (which is the sign of getting false positive and false negative) lower than two other tools. The great value for F1 score is 1 and between the other tools (TextBlob and Vader), Vader with higher accuracy and higher F1 score seems to have better performance for my sentiment identification.    \n",
        "\n",
        "\n"
      ]
    }
  ]
}